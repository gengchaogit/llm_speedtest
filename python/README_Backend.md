# 🐍 LLM速度测试工具 - Python后端版 v2.2

## 简介

Python后端版本通过Python FastAPI后端发起HTTP请求，突破浏览器6并发限制，支持真正的高并发测试（50+并发）。

## 与浏览器版本对比

| 特性 | 浏览器版本 | Python后端版本 |
|------|-----------|---------------|
| 安装要求 | 无需安装 | 需要Python 3.7+ |
| 并发限制 | ≤6 (浏览器限制) | 50+ (无限制) |
| 测试准确性 | 一般 | 高 (真实并发) |
| 启动方式 | 双击HTML | 需启动后端服务 |
| 适用场景 | 快速测试 | 高并发压测 |

## 安装说明

### 系统要求
- Python 3.7 或更高版本
- Windows / Linux / macOS

### 安装依赖

```bash
cd python
pip install fastapi uvicorn httpx
```

**使用国内镜像加速（可选）：**
```bash
pip install fastapi uvicorn httpx -i https://pypi.tuna.tsinghua.edu.cn/simple
```

## 使用方法

### 方法一：一键启动（推荐）

#### Windows用户
双击以下任一脚本：
- `启动测速工具.bat` (中文界面)
- `Start_LLM_Speed_Test.bat` (英文界面)

脚本会自动：
1. 检查Python环境
2. 安装缺失的依赖包
3. 启动后端服务器
4. 在默认浏览器打开测试页面

#### Linux/macOS用户
创建启动脚本：
```bash
#!/bin/bash
cd python
python llm_test_backend.py &
sleep 2
open LLM_Speed_Test_v2_Python_Backend.html  # macOS
# xdg-open LLM_Speed_Test_v2_Python_Backend.html  # Linux
```

### 方法二：手动启动

#### 1. 启动后端服务器

```bash
cd python
python llm_test_backend.py
```

后端服务将运行在 `http://localhost:18000` (默认端口，可自动调整)

#### 2. 打开前端页面

在浏览器中打开 `LLM_Speed_Test_v2_Python_Backend.html`

## 配置说明

### 后端配置

#### 端口配置

后端服务会**自动选择一个未占用的随机端口**，避免端口冲突。端口信息会自动传递给前端HTML页面。

如需手动指定端口，可以在启动时传递端口参数：

```bash
python llm_test_backend.py 8080  # 使用指定端口8080
```

#### CORS配置

编辑 `llm_test_backend.py` 中的CORS配置（如需修改）：

```python
# CORS配置（跨域）
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # 生产环境建议限制来源
    ...
)
```

### 前端配置

前端页面会自动从URL参数接收后端端口信息。如需手动修改后端地址，可以在页面顶部的**"Python后端地址"**输入框中修改。

前端页面的所有功能与浏览器版本相同，包括：
- 后端地址配置（支持手动修改）
- API地址、模型名称、并发数等参数配置
- 历史记录管理
- 图表导出
- CSV导出/导入

## 主要功能

### 1. 突破并发限制
- 浏览器版本受限于浏览器的6并发限制
- Python后端版本可支持50+并发，测试真实的系统并发能力

### 2. 更准确的吞吐量计算
- 使用真实的墙上时间计算总吞吐量
- 记录每个请求的精确时间戳（开始时间、首token时间、结束时间）
- 计算公式：
  - Prefill总吞吐 = 总prompt tokens / (最晚首token时间 - 最早开始时间)
  - Decode总吞吐 = 总output tokens / (最晚结束时间 - 最早首token时间)

### 3. TTFT与ITL延迟测量 (v2.2新增)
- **TTFT (Time To First Token)**：首Token延迟，衡量模型响应速度
- **ITL (Inter-Token Latency)**：Token间延迟，衡量生成流畅度
  - 平均值：所有token间隔的平均时间
  - 标准差：衡量生成稳定性/抖动（jitter）
- 独立图表展示TTFT和ITL随提示词长度的变化趋势

### 4. 完整的6图表体系 (v2.2新增)
测试结果提供6个维度的可视化分析：
1. **Prefill吞吐图表**：预填充速度随提示词长度变化
2. **Decode吞吐图表**：输出速度随提示词长度变化
3. **TTFT图表**：首Token延迟随提示词长度变化
4. **ITL图表**：Token间延迟（平均值+标准差）
5. **Prefill百分位图表**：P50/P90/P95吞吐分布
6. **Decode百分位图表**：P50/P90/P95吞吐分布

### 5. 历史记录对比功能 (v2.2增强)
- 支持勾选多条历史记录生成对比图表
- **完整6图表对比**：对比所有维度的性能差异
  - Prefill/Decode吞吐对比
  - TTFT/ITL延迟对比
  - 百分位统计对比（P50/P90/P95用不同线型区分）
- 一键导出所有对比图表为单张长图

### 6. 图表导出功能 (v2.2增强)
- **单次测试导出**：6个图表合并为一张长图导出
- **对比图表导出**：6个对比图表合并导出
- 自动生成包含模型名、并发数、备注的标题

### 7. Token来源追踪
- 显示token统计的来源（API/本地估算）
- 对本地估算值添加⚠警告标记

### 8. 百分位统计
- 显示P50/P90/P95百分位统计
- 更准确评估性能分布和稳定性

### 9. 存储优化
- 未勾选"保存测试详情"时不保存prompt/output文本
- 50并发测试存储占用减少约98%

## 技术架构

### 后端 (llm_test_backend.py)
- **框架**: FastAPI
- **WebSocket**: 实时测试进度推送
- **异步HTTP客户端**: httpx (支持真实高并发)
- **功能**:
  - 接收前端测试请求
  - 并发发起HTTP请求到LLM API
  - 记录精确时间戳
  - 解析响应流并统计tokens
  - 实时推送测试进度

### 前端 (LLM_Speed_Test_v2_Python_Backend.html)
- **通信**: WebSocket连接后端
- **功能**:
  - 配置测试参数
  - 接收实时测试结果
  - 计算真实并发吞吐量
  - 图表展示和数据导出

## 常见问题

### 1. 后端启动失败

**错误**: `Address already in use`

**解决方法**:

v2.2版本已自动使用随机未占用端口，默认优先使用端口**18000**。一般不会遇到端口冲突。如果仍然遇到，可以：

```bash
# 手动指定一个空闲端口
python llm_test_backend.py 8080

# 或查找占用端口的进程
netstat -ano | findstr :18000  # Windows
lsof -i :18000  # Linux/macOS
```

### 2. 前端连接失败

**错误**: WebSocket连接失败

**检查步骤**:
1. 确认后端已启动且运行正常
2. 检查浏览器控制台(F12)查看错误信息
3. 确认页面顶部的"Python后端地址"是否正确（一般会自动设置）
4. 如需手动修改，格式为：`ws://localhost:端口号`（无需添加/ws/test后缀）
5. 检查防火墙设置

### 3. 并发测试结果异常

**可能原因**:
- LLM服务器资源不足（GPU显存、CPU）
- 网络带宽限制
- LLM服务配置的最大batch size限制

**建议**:
- 从较低并发开始测试（如10），逐步增加
- 监控服务器资源使用情况
- 检查LLM服务器日志

### 4. 依赖安装失败

**错误**: `pip install` 失败

**解决方法**:
```bash
# 使用国内镜像
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple fastapi uvicorn httpx

# 或使用清华镜像
pip install -i https://pypi.mirrors.ustc.edu.cn/simple fastapi uvicorn httpx
```

## 停止服务

### Windows
关闭后端命令行窗口即可停止服务

### Linux/macOS
在后端终端按 `Ctrl+C` 停止服务

## 性能建议

### 并发数设置
- **测试开始**: 建议从10并发开始
- **逐步增加**: 每次增加10-20并发
- **监控观察**: 注意服务器负载和响应时间
- **找到上限**: 当延迟明显增加时即为系统瓶颈

### 提示词长度
- **短提示词测试** (128-1024): 测试Prefill性能
- **长提示词测试** (4096-32768): 测试长上下文处理能力
- **超长提示词** (32768+): 测试系统极限

### 输出长度
- **短输出** (128-512): 测试基础Decode性能
- **长输出** (1024-2048): 测试持续生成能力

## 更新日志

### v2.2 (当前版本)

#### Bug修复
- ✅ **图表标题国际化修复**：修复所有图表标题的翻译问题，支持中英文动态切换
  - 非对比模式：6个图表标题（Prefill/Decode/TTFT/ITL/百分位）完整翻译
  - 对比模式：6个对比图表标题完整翻译
  - Y轴标签：吞吐/时间单位的翻译
  - 解决英文模式下仍显示中文标题的问题
- ✅ **文件名优化**：全面优化导出文件名生成逻辑
  - 兼容Windows/Linux/macOS文件名限制（正确处理禁止字符`< > : " / \ | ? *`）
  - 移除所有特殊字符（+、括号、冒号等）
  - 防止中文字符截断问题（使用`substring`而非`slice`）
  - 添加时间戳避免文件覆盖（格式：2025-12-30_14_30_45）
  - 优化文件名长度（限制在200字符以内，确保跨平台兼容）
  - 影响范围：CSV导出、历史记录CSV导出、图表导出、对比图表导出

#### 新增功能
- ✅ **TTFT测量**：新增首Token时间(Time To First Token)测量，独立图表展示
- ✅ **ITL测量**：新增Token间延迟(Inter-Token Latency)测量
  - 平均值：衡量整体生成速度
  - 标准差：衡量生成稳定性/抖动
- ✅ **6图表体系**：测试结果提供完整6个维度的可视化分析
- ✅ **完整对比功能**：历史记录对比现在支持全部6个图表的对比
  - Prefill/Decode吞吐对比
  - TTFT/ITL延迟对比
  - 百分位统计对比（P50/P90/P95）
- ✅ **增强导出功能**：
  - 单次测试导出所有6个图表为一张长图
  - 对比图表导出所有6个对比图表为一张长图

#### 基础架构
- ✅ **智能端口选择**：默认使用端口18000（避开常见端口），被占用时自动选择随机端口
- ✅ **端口自动传递**：启动脚本自动捕获端口并传递给HTML前端
- ✅ **前端显示配置**：HTML页面可显示和修改后端地址
- ✅ **手动端口指定**：支持通过命令行参数手动指定端口
- ✅ **历史记录保持**：使用固定默认端口，确保localStorage历史记录不丢失

#### v2.1版本的关键修复
- ✅ **修复并发吞吐量计算**（关键修复）：
  - 使用基于真实时间戳的墙上时间计算总吞吐量
  - 正确处理并发请求的时间重叠
  - Prefill吞吐 = 总tokens / (最晚首token时间 - 最早开始时间)
  - Decode吞吐 = 总tokens / (最晚结束时间 - 最早首token时间)
- ✅ 修复图表导出按钮的翻译变量作用域问题
- ✅ 修复加载历史记录时的图表标题显示

### v2.1
- ✅ 初始发布Python后端版本
- ✅ 支持50+真实高并发测试
- ✅ 修复并发吞吐量计算错误
- ✅ 添加Token来源追踪
- ✅ 添加百分位统计(P50/P90/P95)
- ✅ 优化存储空间占用
- ✅ 提供一键启动脚本

## 技术支持

- **GitHub**: https://github.com/gengchaogit/llm_speedtest
- **QQ群**: 1028429001
- **Issues**: 欢迎在GitHub提交问题和建议

## 许可证

本项目基于原作者纸鸢随风（B站）的工作进行改进

---

**开发者**: chao (魔改版维护者)
**版本**: v2.2
**最后更新**: 2025-12-30
